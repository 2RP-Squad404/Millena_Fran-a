# Relatório de Estudos
**Nome do Estágiario:** Millena França
**Data:** 07/08

**Módulos/Etapas Feitas:**  
1. **Engenharia de Dados**
2. **BigData**
3. **Modelagem de Dados**

## Resumo dos módulos 
## Engenharia de Dados

Transformar dados brutos em informações úteis, que podem ser utilizados para  a tomada de decisões, análises e etc. Extrair tudo possível a partir dos dados que já tenho.
Processos de coleta, armazenamento e distribuição dos dados são tarefas necessárias para projetar soluções a partir dos bancos de dados e alinhar essas soluções aos objetivos da empresa.

### Pipeline de Dados
É uma série de etapas de processamento para preparar melhor os dados para a análise. Um pipeline de dados inclui diversas tecnologias para verificar, resumir e encontrar padrões nos dados. 

#### Benefícios
- **Melhor qualidade dos dados:** Limpam e refinam dados brutos, padronizam e garantem consistência.
- **Processamento eficiente:** automatização de tarefas de transformação de dados 
- **Integração de dados abrangente:** Cruza dados de várias fontes para obter resultados mais consistentes, sem irregularidades

#### Como Funciona
Extrai os dados de uma fonte, faz alterações e os salva em um destino especifico. 
- **Transformações:** São operações (como classificação, reformatação, verificação e validação). O pipeline pode filtrar, resumir ou processar dados para atender os requisitos da análise.
- **Destinos:** O endpoint de um pipeline de dados pode ser um data warehouse, data lake ou outra aplicação de análise de dados.

### Ferramentas Comuns na Engenharia de Dados
- **Bancos de Dados:** MySQL, PostgreSQL, MongoDB, Cassandra
- **Data Warehousing:** Amazon Redshift, Google BigQuery, Snowflake
- **Processamento de Dados:** Apache Hadoop, Apache Spark, Apache Flink, Tensor Flow
- **Ferramentas ETL (Extract, Transform, Load):** Apache Nifi, Apache Airflow, Airbyte, Dataflow
- **Linguagens de Programação:** Python, SQL, Java, Scala, R.
- **Ferramentas para Armazenar Dados:** Hadoop Distributed File System (HDFS), Amazon S3, Google Cloud Storage, Microsoft Azure Blob Storage.

### Tipos de Dados
Dados são conjuntos de informações que podem ser coletados, analisados e utilizados para tomada de decisões
- **Estruturados:** possuem padrão específico (tabela).
- **Não Estruturados:** sem padrão (texto, vídeos, e-mails, músicas).
- **Semi Estruturados:** dados separados, parcialmente organizados.

### Locais de Armazenamento de Dados
- **Data Warehouse:** Sistema de armazenamento projetado para coletar, organizar e analisar grandes volumes de dados. Criado para lidar com dados estruturados.
Ele é ideal para análises históricas e complexas, permitindo que as organizações realizem consultas intensivas e relatórios detalhados. são mais comumente usados
para análises retrospectivas onde os dados já foram processados e organizados para consulta, assim economizando espaço com dados que poderiam nunca ser usados.
- **Data Lake:** O Data Lake pode ser visto como um repositório centralizado para armazenar dados estruturados e não estruturados. Ele pode armazenar dados não
processados sem que haja a necessidade de nenhum tipo de transformação.

## Big Data
é um conjunto de tecnologias e práticas usadas para coletar, armazenar, processar e analisar grandes volumes de dados que não podem ser gerenciados de maneira eficiente com
as ferramentas tradicionais de banco de dados.

### 4 Vs
1. **Volume:** A quantidade de dados gerada e coletada é enorme, muitas vezes medida em petabytes ou exabytes.
2. **Variedade:** Os dados vêm de diversas fontes e podem ser estruturados, semiestruturados ou não estruturados (por exemplo, texto, vídeo, áudio, sensores, etc.).
3. **Velocidade:** A velocidade com que novos dados são gerados e precisam ser processados é alta.
4. **Veracidade:** A qualidade e a confiabilidade dos dados podem variar, exigindo técnicas para lidar com incertezas e garantir a precisão.

**Aplicações**
- **Negócios:** Análise de comportamento do consumidor, personalização de marketing, otimização de processos empresariais.
- **Saúde:** Análise de dados genômicos, monitoramento de epidemias, medicina personalizada.
- **Governo:** Análise de políticas públicas, prevenção de crimes, gerenciamento de cidades inteligentes.
- **Ciências:** Pesquisa científica, análise de dados astronômicos, estudos climáticos.

### Apache Spark
é um mecanismo de análise unificado para processamento de dados em grande escala com módulos integrados para SQL, streaming, machine learning e processamento de gráficos.
O Spark pode ser executado no Apache Hadoop,Apache Mesos, Kubernetes, por conta própria, na nuvem e em diversas fontes de dados.

### Etapas do Processamento de Dados
1. **Aquisição de Dados**
Após estabelecer seus objetivos e identificar que tipo de dados eles precisam para encontrar respostas e como adquirir todos os dados. Escolher os métodos adequados para acessá-los.

2. **Exploração/Pré-processamento**
Compreender os dados, reconhecer tendências. Verificar inconstâncias, entender correlações entre as variáveis. Depois de entender, classificá-los por tipo, frequência, etc.
Por fim, análise informada,podemos remover os registros com valores ausentes, mesclar registros duplicados ou, se adequado, podemos gerar a melhor estimativa para valores inválidos.

3. **Análise de Dados**

**Categorias de técnicas de análise:**
- **Classificação:** para prever a categoria dos dados de entrada
- **Regressão:** prever um valor numérico
- **Agrupamento:** organizar itens semelhantes em grupos
- **Análise de associação:** encontrar regras para capturar a associação entre itens (ex: análise de cesta de mercado)
- **Análise de grafos:** usar estruturas de grafos para encontrar conexões entre entidades

Nos modelos de Classificação e Regressão, comparamos os valores previstos com o valor correto para avaliar o modelo.
No agrupamento, os resultados devem ser comparados com os objetivos do negócio

4. **Relatando Insights**

Apresentar descobertas.

## Modelagem de Dados
usado para definir as características dos formatos de dados, estruturas e funções de processamento de banco de dados para atender com eficiência os requisitos do fluxo de dados.

### Tipos de Modelagem de Dados
1. **Modelo Conceitual:** Representa uma visão de alto nível dos requisitos de dados do negócio.
Focado na organização e definição dos principais conceitos e relações sem considerar detalhes técnicos. Ferramenta comum: Diagrama de Entidade-Relacionamento (ERD).

2. **Modelo Lógico:** Detalha o modelo conceitual para descrever a estrutura lógica dos dados, incluindo tipos de dados, atributos, e as relações entre entidades de forma mais técnica,
mas ainda sem considerar implementações físicas.

3. **Modelo Físico:** Define como o modelo lógico será implementado em um sistema de banco de dados específico. Inclui detalhes sobre tabelas, índices, chaves primárias e estrangeiras,
além de outros aspectos técnicos de armazenamento.

### Processo de Modelagem de Dados
Inerentemente, a modelagem de dados é um processo top-down, que começa com o modelo conceitual para estabelecer a visão geral, passa para o modelo lógico e, finalmente,
para o projeto detalhado contido no modelo físico.

1. **Coleta de Requisitos:** Identificar e documentar os requisitos de dados com base nas necessidades do negócio.
2. **Criação do Modelo Conceitual:** Usar diagramas ER ou outras ferramentas para representar entidades e relações.
3. **Criação do Modelo Lógico:** Detalhar o modelo conceitual com atributos, tipos de dados e relacionamentos.
4. **riação do Modelo Físico:** Converter o modelo lógico em um esquema de banco de dados real, especificando detalhes de implementação.
5. **Validação e Refinamento:** Verificar se o modelo atende aos requisitos e realizar ajustes conforme necessário.
6. **Implementação:** Implementar o modelo físico em um sistema de banco de dados e configurar os dados de acordo com o modelo.

### Importância
O modelo de dados abrangente e otimizado ajuda a criar um banco de dados lógico e simplificado que elimina redundâncias,
reduz os requisitos de armazenamento e permite a recuperação eficiente.

### Ferrametas de Modelagem de Dados
- **ER/Studio**
- **IBM InfoSphere Data Architect**
- **Microsoft Visio**
- **Oracle SQL Developer Data Modeler**
- **PowerDesigner**
- **MySQL Workbench**

Um modelo de dados completo e bem pensado é o segredo do desenvolvimento de um banco de dados verdadeiramente funcional, útil, seguro e preciso.

## Análise de Dados
Processo de inspecionar, limpar e modelar dados com o objetivo de descobrir informações úteis, tirar conclusões e apoiar a tomada de decisões.

### Processo
1. **Coleta de Dados:** reunir dados de diferentes fontes, garantindo que os mesmos sejam uteis  e representativos para o objetivo.
2. **Preparação e Limpeza de Dados:** limpeza dos dados sujos, eliminar dados duplicados, tratar valores ausentes e realizar formatação, garantir consistência, resultados confiáveis.
3. **Exploração de Dados:** entender características principais dos dados, padrões e relações. Identificar tendências, padrões e anomalias.
4. **Análise Descritiva:** descrever as características do dados através de estatísticas (média, mediana, desvio padrão e frequência). Tem como objetivo fornecer uma visão clara dos dados.
5. **Análise Diagnóstica:** investigar porque tal evento aconteceu.
6. **Análise Preditiva:** com a ajuda do machine learning, prever um futuro com base em dados históricos.
7. **Análise Prescritiva:** sugerir alterações específicas para obter o resultado desejado. Recomendações para melhorar processos
8. **Visualização de Dados:** representação gráfica dos dados para facilitar a compreensão e interpretação, tornando os dados mais acessíveis.
9. **Modelagem de Dados:** construção de modelos para representar e analisar os dados
10. **Interpretação e Comunicação:** comunicar os insights obtidos dos dados (resultados), podendo assim tomar decisões estratégicas.

### Ferramentas e Técnicas
- **Ferramentas de Análise**: Softwares e plataformas como Excel, R, Python (pandas, numpy), SQL, Tableau, Power BI e Google Data Studio.
- **Técnicas Estatísticas**: Testes de hipóteses, análise de regressão, análise de variância (ANOVA), correlação e outras técnicas estatísticas.
- **Algoritmos de Machine Learning**: Regressão, árvores de decisão, redes neurais, clustering (k-means, DBSCAN) e outros.

### Diferenças entre Modelagem de Dados e Análise de Dados
- **Modelagem de Dados** é sobre a **estruturação** e **organização** dos dados para que possam ser armazenados e gerenciados de forma eficiente.
- **Análise de Dados** é sobre **examinar** e **interpretar** os dados para extrair informações úteis e apoiar a tomada de decisões.


**Desafios Encontrados:**  
Diferenciar os métodos de organização e manipulação dos dados.

**Feedback e Ajustes:**  
Mais indicações de materiais para o estudo dos assuntos, principalmente artigos.

**Próximos Passos:**  
Vou entrar na parte de Linguagens e Frameworks, BigQuery e Transacional
